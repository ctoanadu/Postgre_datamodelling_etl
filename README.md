# Data-Engineer-Project

# Data Modelling with Postgres

## Overview
A startup called spakify wants to analyze the data on songs and users onbtained from the new music streaming app. The data collected is in json format. In this project we used data modelling with postgres and performed an ETL with python to have an insight on what songs users are listening too.

## Datasets
The dataset used for this project are song and log datasets.
### 1. Song dataset
This is a subset of real data from the million song dataset. Each files is on json format and contains metadata about a song and the artist of the song.
### 2. Log dataset
This consist of log files in json format generated by the even simulator based on songs in the data set.

## Database Schema
A star scheme was used to model this database. It consist of a fact table and four dimention tables.
### 1. Fact Table
It consist of records in log data associated with songsplay i.e records with page 'Nextsong'.
### 2. Dimension Table
These tables are connected to the fact table 'songplays'. They include 'users','songs','artist' and 'time'.

## ETL pipeline
I extracted data form the song and log dataset and inserted them into the fact and dimension tables.

## Project File
1. **test.ipynb**- This file used to check database connected and check if tables were created and data inserted in tables.
2. **data**- Contains the song dataset and log dataset.
3. **etl.ipynb**- Processes and loads g=the json files inot its respective tables.
4. **create_table.py**- It executes scripts to create the database connection and drop tables.
5. **etl.py**- It executes scripts to complete the ETL process.
6. **sql_query.py**- This script creates and inserts data into tables.
7. **READme**- Docuentation of the project.

### How to run the project
1. Execute the create_table.py script to drop and previous database and create a new database with tables.
2. Execute the etl.py to extract the json file format in song and log dataset and inserts the data into the fact and dimension table.


